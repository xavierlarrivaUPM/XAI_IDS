{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee72e08-eb6a-43af-9839-aa3885a8dd00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:18:00.246869Z",
     "iopub.status.busy": "2023-06-21T06:18:00.246498Z",
     "iopub.status.idle": "2023-06-21T06:18:03.488751Z",
     "shell.execute_reply": "2023-06-21T06:18:03.487119Z",
     "shell.execute_reply.started": "2023-06-21T06:18:00.246842Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install imbalanced-learn > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5252d8d-64e5-44d4-a8a1-b81d11ceef01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:18:03.490989Z",
     "iopub.status.busy": "2023-06-21T06:18:03.490694Z",
     "iopub.status.idle": "2023-06-21T06:18:06.919326Z",
     "shell.execute_reply": "2023-06-21T06:18:06.918576Z",
     "shell.execute_reply.started": "2023-06-21T06:18:03.490962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d3da2-c0f1-46eb-81cf-e80ef4f3e210",
   "metadata": {},
   "source": [
    "## 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbf036e-a2db-434f-8ddc-da10206d7ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:18:06.920753Z",
     "iopub.status.busy": "2023-06-21T06:18:06.920283Z",
     "iopub.status.idle": "2023-06-21T06:18:07.383127Z",
     "shell.execute_reply": "2023-06-21T06:18:07.382354Z",
     "shell.execute_reply.started": "2023-06-21T06:18:06.920729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123504, 22)\n",
      "(123504,)\n",
      "(41169, 22)\n",
      "(41169,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top003_train_encoded.csv\")\n",
    "test = pd.read_csv(\"/notebooks/FinalDataset/top003_test_encoded.csv\")\n",
    "\n",
    "x_train = train.drop('attack_cat', axis=1)\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "x_test = test.drop('attack_cat', axis=1)\n",
    "y_test = test['attack_cat']\n",
    "\n",
    "del train, test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc939b-94e5-4d7b-a08c-0a788a87e03f",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5295cab3-24d4-4973-bbc6-0ace4d097222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:18:07.384678Z",
     "iopub.status.busy": "2023-06-21T06:18:07.384447Z",
     "iopub.status.idle": "2023-06-21T06:24:41.010839Z",
     "shell.execute_reply": "2023-06-21T06:24:41.009814Z",
     "shell.execute_reply.started": "2023-06-21T06:18:07.384657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    35.720301\n",
      "3    27.098717\n",
      "4    14.728268\n",
      "2     9.930852\n",
      "6     8.494462\n",
      "0     1.629097\n",
      "1     1.413719\n",
      "7     0.887421\n",
      "8     0.097163\n",
      "Name: attack_cat, dtype: float64\n",
      "Epoch 1/5000\n",
      "3860/3860 [==============================] - 13s 3ms/step - loss: 0.9045 - accuracy: 0.6567 - val_loss: 0.8483 - val_accuracy: 0.6726\n",
      "Epoch 2/5000\n",
      "3860/3860 [==============================] - 11s 3ms/step - loss: 0.8230 - accuracy: 0.6980 - val_loss: 0.8033 - val_accuracy: 0.7077\n",
      "Epoch 3/5000\n",
      "3860/3860 [==============================] - 11s 3ms/step - loss: 0.7896 - accuracy: 0.7121 - val_loss: 0.7786 - val_accuracy: 0.7286\n",
      "Epoch 4/5000\n",
      "3860/3860 [==============================] - 11s 3ms/step - loss: 0.7708 - accuracy: 0.7192 - val_loss: 0.7728 - val_accuracy: 0.7175\n",
      "Epoch 5/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7602 - accuracy: 0.7235 - val_loss: 0.7556 - val_accuracy: 0.7276\n",
      "Epoch 6/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7513 - accuracy: 0.7271 - val_loss: 0.7591 - val_accuracy: 0.7278\n",
      "Epoch 7/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7485 - accuracy: 0.7269 - val_loss: 0.7400 - val_accuracy: 0.7368\n",
      "Epoch 8/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7428 - accuracy: 0.7303 - val_loss: 0.7845 - val_accuracy: 0.7064\n",
      "Epoch 9/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7390 - accuracy: 0.7295 - val_loss: 0.7375 - val_accuracy: 0.7320\n",
      "Epoch 10/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7362 - accuracy: 0.7312 - val_loss: 0.7387 - val_accuracy: 0.7332\n",
      "Epoch 11/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7340 - accuracy: 0.7312 - val_loss: 0.7264 - val_accuracy: 0.7366\n",
      "Epoch 12/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7292 - accuracy: 0.7334 - val_loss: 0.7543 - val_accuracy: 0.7174\n",
      "Epoch 13/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7279 - accuracy: 0.7332 - val_loss: 0.7256 - val_accuracy: 0.7355\n",
      "Epoch 14/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7251 - accuracy: 0.7340 - val_loss: 0.7490 - val_accuracy: 0.7143\n",
      "Epoch 15/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7223 - accuracy: 0.7345 - val_loss: 0.7329 - val_accuracy: 0.7279\n",
      "Epoch 16/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7199 - accuracy: 0.7359 - val_loss: 0.7193 - val_accuracy: 0.7330\n",
      "Epoch 17/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7180 - accuracy: 0.7371 - val_loss: 0.7211 - val_accuracy: 0.7384\n",
      "Epoch 18/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7162 - accuracy: 0.7376 - val_loss: 0.7149 - val_accuracy: 0.7389\n",
      "Epoch 19/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7144 - accuracy: 0.7377 - val_loss: 0.7143 - val_accuracy: 0.7389\n",
      "Epoch 20/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7115 - accuracy: 0.7397 - val_loss: 0.7357 - val_accuracy: 0.7304\n",
      "Epoch 21/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7116 - accuracy: 0.7390 - val_loss: 0.7203 - val_accuracy: 0.7388\n",
      "Epoch 22/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7100 - accuracy: 0.7394 - val_loss: 0.7137 - val_accuracy: 0.7382\n",
      "Epoch 23/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7089 - accuracy: 0.7393 - val_loss: 0.7138 - val_accuracy: 0.7440\n",
      "Epoch 24/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7076 - accuracy: 0.7410 - val_loss: 0.7055 - val_accuracy: 0.7494\n",
      "Epoch 25/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7063 - accuracy: 0.7408 - val_loss: 0.7043 - val_accuracy: 0.7429\n",
      "Epoch 26/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7037 - accuracy: 0.7425 - val_loss: 0.7013 - val_accuracy: 0.7486\n",
      "Epoch 27/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7028 - accuracy: 0.7428 - val_loss: 0.7110 - val_accuracy: 0.7295\n",
      "Epoch 28/5000\n",
      "3860/3860 [==============================] - 11s 3ms/step - loss: 0.7027 - accuracy: 0.7424 - val_loss: 0.6930 - val_accuracy: 0.7491\n",
      "Epoch 29/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7000 - accuracy: 0.7442 - val_loss: 0.7028 - val_accuracy: 0.7467\n",
      "Epoch 30/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7001 - accuracy: 0.7430 - val_loss: 0.7041 - val_accuracy: 0.7447\n",
      "Epoch 31/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.7003 - accuracy: 0.7436 - val_loss: 0.7121 - val_accuracy: 0.7399\n",
      "Epoch 32/5000\n",
      "3860/3860 [==============================] - 11s 3ms/step - loss: 0.6988 - accuracy: 0.7453 - val_loss: 0.6935 - val_accuracy: 0.7463\n",
      "Epoch 33/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6973 - accuracy: 0.7451 - val_loss: 0.7050 - val_accuracy: 0.7422\n",
      "1287/1287 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.11      0.18       665\n",
      "           1       0.00      0.00      0.00       583\n",
      "           2       0.41      0.08      0.13      4088\n",
      "           3       0.58      0.84      0.69     11057\n",
      "           4       0.73      0.77      0.75      6056\n",
      "           5       1.00      0.97      0.99     14755\n",
      "           6       0.60      0.62      0.61      3496\n",
      "           7       0.00      0.00      0.00       415\n",
      "           8       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.75     41169\n",
      "   macro avg       0.43      0.38      0.37     41169\n",
      "weighted avg       0.72      0.75      0.72     41169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_ohe.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(x_train, y_train_ohe, validation_data=(x_test, y_test_ohe), epochs=5000, callbacks=[early_stopping])\n",
    "model.save('/notebooks/Models/MLP/MLP_003_Unbalanced.h5')\n",
    "\n",
    "model = load_model(\"/notebooks/Models/MLP/MLP_003_Unbalanced.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77575c58-bbf5-47f0-bdac-fd28bcb3fc31",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b041a633-7bb6-40ae-8715-5a6a295b5b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:24:41.013819Z",
     "iopub.status.busy": "2023-06-21T06:24:41.013026Z",
     "iopub.status.idle": "2023-06-21T06:35:08.033538Z",
     "shell.execute_reply": "2023-06-21T06:35:08.032534Z",
     "shell.execute_reply.started": "2023-06-21T06:24:41.013792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11.111111\n",
      "5    11.111111\n",
      "0    11.111111\n",
      "6    11.111111\n",
      "7    11.111111\n",
      "8    11.111111\n",
      "2    11.111111\n",
      "4    11.111111\n",
      "3    11.111111\n",
      "Name: attack_cat, dtype: float64\n",
      "Epoch 1/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.3795 - accuracy: 0.4674 - val_loss: 1.1705 - val_accuracy: 0.5312\n",
      "Epoch 2/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.2507 - accuracy: 0.5067 - val_loss: 1.0478 - val_accuracy: 0.6283\n",
      "Epoch 3/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.1879 - accuracy: 0.5270 - val_loss: 1.0086 - val_accuracy: 0.6273\n",
      "Epoch 4/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.1591 - accuracy: 0.5375 - val_loss: 0.9957 - val_accuracy: 0.6364\n",
      "Epoch 5/5000\n",
      "12408/12408 [==============================] - 35s 3ms/step - loss: 1.1379 - accuracy: 0.5462 - val_loss: 0.9813 - val_accuracy: 0.6136\n",
      "Epoch 6/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.1223 - accuracy: 0.5535 - val_loss: 1.0075 - val_accuracy: 0.6249\n",
      "Epoch 7/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.1100 - accuracy: 0.5619 - val_loss: 0.9708 - val_accuracy: 0.6601\n",
      "Epoch 8/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.0993 - accuracy: 0.5689 - val_loss: 0.9282 - val_accuracy: 0.6790\n",
      "Epoch 9/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0911 - accuracy: 0.5735 - val_loss: 0.9626 - val_accuracy: 0.6801\n",
      "Epoch 10/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0853 - accuracy: 0.5764 - val_loss: 0.9514 - val_accuracy: 0.6207\n",
      "Epoch 11/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0791 - accuracy: 0.5788 - val_loss: 0.9756 - val_accuracy: 0.6398\n",
      "Epoch 12/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0726 - accuracy: 0.5813 - val_loss: 0.9280 - val_accuracy: 0.6241\n",
      "Epoch 13/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.0673 - accuracy: 0.5832 - val_loss: 0.9657 - val_accuracy: 0.6029\n",
      "Epoch 14/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0625 - accuracy: 0.5856 - val_loss: 0.9723 - val_accuracy: 0.6598\n",
      "Epoch 15/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.0578 - accuracy: 0.5872 - val_loss: 0.9856 - val_accuracy: 0.5949\n",
      "Epoch 16/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0534 - accuracy: 0.5878 - val_loss: 0.9609 - val_accuracy: 0.6412\n",
      "Epoch 17/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 1.0505 - accuracy: 0.5892 - val_loss: 0.9812 - val_accuracy: 0.6405\n",
      "1287/1287 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.27      0.13       665\n",
      "           1       0.06      0.58      0.11       583\n",
      "           2       0.34      0.13      0.19      4088\n",
      "           3       0.84      0.29      0.43     11057\n",
      "           4       0.70      0.77      0.73      6056\n",
      "           5       1.00      0.97      0.99     14755\n",
      "           6       0.54      0.62      0.57      3496\n",
      "           7       0.11      0.62      0.19       415\n",
      "           8       0.04      0.74      0.07        54\n",
      "\n",
      "    accuracy                           0.62     41169\n",
      "   macro avg       0.41      0.55      0.38     41169\n",
      "weighted avg       0.77      0.62      0.65     41169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_ohe.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(x_train, y_train_ohe, validation_data=(x_test, y_test_ohe), epochs=5000, callbacks=[early_stopping])\n",
    "model.save('/notebooks/Models/MLP/MLP_003_Balanced.h5')\n",
    "\n",
    "model = load_model(\"/notebooks/Models/MLP/MLP_003_Balanced.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7c8b0-008f-4374-b82e-fe777d0c54cf",
   "metadata": {},
   "source": [
    "## 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1baa351-8582-484b-8512-6c4a49dba0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:35:08.035196Z",
     "iopub.status.busy": "2023-06-21T06:35:08.034863Z",
     "iopub.status.idle": "2023-06-21T06:35:09.776269Z",
     "shell.execute_reply": "2023-06-21T06:35:09.775407Z",
     "shell.execute_reply.started": "2023-06-21T06:35:08.035165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123504, 154)\n",
      "(123504,)\n",
      "(41169, 154)\n",
      "(41169,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top002_train_encoded.csv\")\n",
    "test = pd.read_csv(\"/notebooks/FinalDataset/top002_test_encoded.csv\")\n",
    "\n",
    "x_train = train.drop('attack_cat', axis=1)\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "x_test = test.drop('attack_cat', axis=1)\n",
    "y_test = test['attack_cat']\n",
    "\n",
    "del train, test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae690583-6a4b-48ae-b227-cce06fa9a8d1",
   "metadata": {},
   "source": [
    "## Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d4512e-4f76-4959-bef2-9d33a5490395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:35:09.777518Z",
     "iopub.status.busy": "2023-06-21T06:35:09.777287Z",
     "iopub.status.idle": "2023-06-21T06:43:10.355027Z",
     "shell.execute_reply": "2023-06-21T06:43:10.354083Z",
     "shell.execute_reply.started": "2023-06-21T06:35:09.777497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    35.720301\n",
      "3    27.098717\n",
      "4    14.728268\n",
      "2     9.930852\n",
      "6     8.494462\n",
      "0     1.629097\n",
      "1     1.413719\n",
      "7     0.887421\n",
      "8     0.097163\n",
      "Name: attack_cat, dtype: float64\n",
      "Epoch 1/5000\n",
      "3860/3860 [==============================] - 13s 3ms/step - loss: 0.7335 - accuracy: 0.7328 - val_loss: 0.6741 - val_accuracy: 0.7443\n",
      "Epoch 2/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6660 - accuracy: 0.7532 - val_loss: 0.6526 - val_accuracy: 0.7611\n",
      "Epoch 3/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6496 - accuracy: 0.7589 - val_loss: 0.6429 - val_accuracy: 0.7631\n",
      "Epoch 4/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6408 - accuracy: 0.7612 - val_loss: 0.6415 - val_accuracy: 0.7626\n",
      "Epoch 5/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6306 - accuracy: 0.7646 - val_loss: 0.6411 - val_accuracy: 0.7637\n",
      "Epoch 6/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6239 - accuracy: 0.7669 - val_loss: 0.6238 - val_accuracy: 0.7681\n",
      "Epoch 7/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6175 - accuracy: 0.7689 - val_loss: 0.6238 - val_accuracy: 0.7695\n",
      "Epoch 8/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6127 - accuracy: 0.7699 - val_loss: 0.6071 - val_accuracy: 0.7740\n",
      "Epoch 9/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6070 - accuracy: 0.7724 - val_loss: 0.6088 - val_accuracy: 0.7690\n",
      "Epoch 10/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6047 - accuracy: 0.7721 - val_loss: 0.6018 - val_accuracy: 0.7786\n",
      "Epoch 11/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5998 - accuracy: 0.7733 - val_loss: 0.6140 - val_accuracy: 0.7689\n",
      "Epoch 12/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5961 - accuracy: 0.7751 - val_loss: 0.6199 - val_accuracy: 0.7621\n",
      "Epoch 13/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5932 - accuracy: 0.7758 - val_loss: 0.5928 - val_accuracy: 0.7774\n",
      "Epoch 14/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5893 - accuracy: 0.7778 - val_loss: 0.6266 - val_accuracy: 0.7690\n",
      "Epoch 15/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5875 - accuracy: 0.7779 - val_loss: 0.5845 - val_accuracy: 0.7816\n",
      "Epoch 16/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5844 - accuracy: 0.7787 - val_loss: 0.5952 - val_accuracy: 0.7610\n",
      "Epoch 17/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5832 - accuracy: 0.7785 - val_loss: 0.5806 - val_accuracy: 0.7820\n",
      "Epoch 18/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5805 - accuracy: 0.7793 - val_loss: 0.5882 - val_accuracy: 0.7814\n",
      "Epoch 19/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5771 - accuracy: 0.7817 - val_loss: 0.5850 - val_accuracy: 0.7758\n",
      "Epoch 20/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5774 - accuracy: 0.7810 - val_loss: 0.5944 - val_accuracy: 0.7750\n",
      "Epoch 21/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5746 - accuracy: 0.7819 - val_loss: 0.5716 - val_accuracy: 0.7792\n",
      "Epoch 22/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5737 - accuracy: 0.7818 - val_loss: 0.5784 - val_accuracy: 0.7852\n",
      "Epoch 23/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5713 - accuracy: 0.7824 - val_loss: 0.5733 - val_accuracy: 0.7856\n",
      "Epoch 24/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5711 - accuracy: 0.7832 - val_loss: 0.5761 - val_accuracy: 0.7810\n",
      "Epoch 25/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5687 - accuracy: 0.7834 - val_loss: 0.5772 - val_accuracy: 0.7804\n",
      "Epoch 26/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5678 - accuracy: 0.7839 - val_loss: 0.5695 - val_accuracy: 0.7854\n",
      "Epoch 27/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5657 - accuracy: 0.7847 - val_loss: 0.5717 - val_accuracy: 0.7851\n",
      "Epoch 28/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5650 - accuracy: 0.7846 - val_loss: 0.5866 - val_accuracy: 0.7762\n",
      "Epoch 29/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5632 - accuracy: 0.7856 - val_loss: 0.5640 - val_accuracy: 0.7855\n",
      "Epoch 30/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5621 - accuracy: 0.7855 - val_loss: 0.5649 - val_accuracy: 0.7896\n",
      "Epoch 31/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5612 - accuracy: 0.7865 - val_loss: 0.5687 - val_accuracy: 0.7849\n",
      "Epoch 32/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5599 - accuracy: 0.7870 - val_loss: 0.5629 - val_accuracy: 0.7884\n",
      "Epoch 33/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5581 - accuracy: 0.7875 - val_loss: 0.5821 - val_accuracy: 0.7843\n",
      "Epoch 34/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5572 - accuracy: 0.7871 - val_loss: 0.5681 - val_accuracy: 0.7857\n",
      "Epoch 35/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5559 - accuracy: 0.7882 - val_loss: 0.5581 - val_accuracy: 0.7865\n",
      "Epoch 36/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5562 - accuracy: 0.7876 - val_loss: 0.5690 - val_accuracy: 0.7866\n",
      "Epoch 37/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5554 - accuracy: 0.7881 - val_loss: 0.5719 - val_accuracy: 0.7852\n",
      "Epoch 38/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5554 - accuracy: 0.7885 - val_loss: 0.5593 - val_accuracy: 0.7860\n",
      "Epoch 39/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5545 - accuracy: 0.7883 - val_loss: 0.5650 - val_accuracy: 0.7858\n",
      "Epoch 40/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5537 - accuracy: 0.7885 - val_loss: 0.5891 - val_accuracy: 0.7753\n",
      "1287/1287 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.14      0.22       665\n",
      "           1       0.50      0.01      0.01       583\n",
      "           2       0.41      0.13      0.20      4088\n",
      "           3       0.61      0.89      0.73     11057\n",
      "           4       0.83      0.83      0.83      6056\n",
      "           5       1.00      0.98      0.99     14755\n",
      "           6       0.81      0.68      0.74      3496\n",
      "           7       0.54      0.26      0.35       415\n",
      "           8       0.55      0.11      0.18        54\n",
      "\n",
      "    accuracy                           0.79     41169\n",
      "   macro avg       0.66      0.45      0.47     41169\n",
      "weighted avg       0.78      0.79      0.76     41169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_ohe.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(x_train, y_train_ohe, validation_data=(x_test, y_test_ohe), epochs=5000, callbacks=[early_stopping])\n",
    "model.save('/notebooks/Models/MLP/MLP_002_Unbalanced.h5')\n",
    "\n",
    "model = load_model(\"/notebooks/Models/MLP/MLP_002_Unbalanced.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4db732-e473-429d-90cf-25eb2fe04589",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc78ab8-7127-4244-bd03-42fd86fa5178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:43:10.356749Z",
     "iopub.status.busy": "2023-06-21T06:43:10.356504Z",
     "iopub.status.idle": "2023-06-21T06:52:20.086184Z",
     "shell.execute_reply": "2023-06-21T06:52:20.085369Z",
     "shell.execute_reply.started": "2023-06-21T06:43:10.356726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11.111111\n",
      "5    11.111111\n",
      "0    11.111111\n",
      "6    11.111111\n",
      "7    11.111111\n",
      "8    11.111111\n",
      "2    11.111111\n",
      "4    11.111111\n",
      "3    11.111111\n",
      "Name: attack_cat, dtype: float64\n",
      "Epoch 1/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.0825 - accuracy: 0.5660 - val_loss: 0.8731 - val_accuracy: 0.6537\n",
      "Epoch 2/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.9637 - accuracy: 0.6103 - val_loss: 0.8010 - val_accuracy: 0.6965\n",
      "Epoch 3/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.9210 - accuracy: 0.6292 - val_loss: 0.8018 - val_accuracy: 0.6893\n",
      "Epoch 4/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8916 - accuracy: 0.6437 - val_loss: 0.7847 - val_accuracy: 0.7173\n",
      "Epoch 5/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8727 - accuracy: 0.6522 - val_loss: 0.8005 - val_accuracy: 0.6992\n",
      "Epoch 6/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8614 - accuracy: 0.6571 - val_loss: 0.7909 - val_accuracy: 0.7126\n",
      "Epoch 7/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8525 - accuracy: 0.6603 - val_loss: 0.7745 - val_accuracy: 0.7210\n",
      "Epoch 8/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8457 - accuracy: 0.6642 - val_loss: 0.8340 - val_accuracy: 0.6432\n",
      "Epoch 9/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8396 - accuracy: 0.6667 - val_loss: 0.7617 - val_accuracy: 0.7143\n",
      "Epoch 10/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8363 - accuracy: 0.6675 - val_loss: 0.7637 - val_accuracy: 0.7131\n",
      "Epoch 11/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8293 - accuracy: 0.6695 - val_loss: 0.7508 - val_accuracy: 0.7157\n",
      "Epoch 12/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8276 - accuracy: 0.6696 - val_loss: 0.7920 - val_accuracy: 0.7037\n",
      "Epoch 13/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8233 - accuracy: 0.6721 - val_loss: 0.7569 - val_accuracy: 0.7242\n",
      "Epoch 14/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8196 - accuracy: 0.6742 - val_loss: 0.7687 - val_accuracy: 0.7191\n",
      "Epoch 15/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8158 - accuracy: 0.6755 - val_loss: 0.7607 - val_accuracy: 0.7182\n",
      "Epoch 16/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8149 - accuracy: 0.6761 - val_loss: 0.7799 - val_accuracy: 0.7109\n",
      "1287/1287 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.29      0.14       665\n",
      "           1       0.06      0.25      0.10       583\n",
      "           2       0.35      0.52      0.42      4088\n",
      "           3       0.88      0.43      0.58     11057\n",
      "           4       0.88      0.78      0.83      6056\n",
      "           5       1.00      0.97      0.99     14755\n",
      "           6       0.78      0.81      0.80      3496\n",
      "           7       0.30      0.69      0.41       415\n",
      "           8       0.06      0.89      0.11        54\n",
      "\n",
      "    accuracy                           0.72     41169\n",
      "   macro avg       0.49      0.63      0.48     41169\n",
      "weighted avg       0.83      0.72      0.75     41169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_ohe.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(x_train, y_train_ohe, validation_data=(x_test, y_test_ohe), epochs=5000, callbacks=[early_stopping])\n",
    "model.save('/notebooks/Models/MLP/MLP_002_Balanced.h5')\n",
    "\n",
    "model = load_model(\"/notebooks/Models/MLP/MLP_002_Balanced.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f6a99-4cd5-40bd-b99e-7ee140ed7b8c",
   "metadata": {},
   "source": [
    "## 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d13dfe-af88-4638-be01-6b6c73f5ddb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:52:20.087925Z",
     "iopub.status.busy": "2023-06-21T06:52:20.087379Z",
     "iopub.status.idle": "2023-06-21T06:52:22.226106Z",
     "shell.execute_reply": "2023-06-21T06:52:22.225286Z",
     "shell.execute_reply.started": "2023-06-21T06:52:20.087898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123504, 168)\n",
      "(123504,)\n",
      "(41169, 168)\n",
      "(41169,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top001_train_encoded.csv\")\n",
    "test = pd.read_csv(\"/notebooks/FinalDataset/top001_test_encoded.csv\")\n",
    "\n",
    "x_train = train.drop('attack_cat', axis=1)\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "x_test = test.drop('attack_cat', axis=1)\n",
    "y_test = test['attack_cat']\n",
    "\n",
    "del train, test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df329106-16af-4cfd-9505-0222a3384eb8",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a795548-ade1-40f6-9dae-74a92f14ae67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:52:22.227356Z",
     "iopub.status.busy": "2023-06-21T06:52:22.227110Z",
     "iopub.status.idle": "2023-06-21T06:58:03.458523Z",
     "shell.execute_reply": "2023-06-21T06:58:03.457383Z",
     "shell.execute_reply.started": "2023-06-21T06:52:22.227333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    35.720301\n",
      "3    27.098717\n",
      "4    14.728268\n",
      "2     9.930852\n",
      "6     8.494462\n",
      "0     1.629097\n",
      "1     1.413719\n",
      "7     0.887421\n",
      "8     0.097163\n",
      "Name: attack_cat, dtype: float64\n",
      "Epoch 1/5000\n",
      "3860/3860 [==============================] - 13s 3ms/step - loss: 0.7418 - accuracy: 0.7299 - val_loss: 0.6668 - val_accuracy: 0.7574\n",
      "Epoch 2/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6642 - accuracy: 0.7547 - val_loss: 0.6558 - val_accuracy: 0.7583\n",
      "Epoch 3/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6490 - accuracy: 0.7595 - val_loss: 0.6467 - val_accuracy: 0.7604\n",
      "Epoch 4/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6387 - accuracy: 0.7621 - val_loss: 0.6473 - val_accuracy: 0.7598\n",
      "Epoch 5/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6308 - accuracy: 0.7644 - val_loss: 0.6351 - val_accuracy: 0.7626\n",
      "Epoch 6/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6230 - accuracy: 0.7673 - val_loss: 0.6198 - val_accuracy: 0.7699\n",
      "Epoch 7/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6164 - accuracy: 0.7692 - val_loss: 0.6091 - val_accuracy: 0.7706\n",
      "Epoch 8/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6111 - accuracy: 0.7709 - val_loss: 0.6156 - val_accuracy: 0.7711\n",
      "Epoch 9/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6062 - accuracy: 0.7721 - val_loss: 0.6122 - val_accuracy: 0.7694\n",
      "Epoch 10/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.6008 - accuracy: 0.7740 - val_loss: 0.5970 - val_accuracy: 0.7736\n",
      "Epoch 11/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5979 - accuracy: 0.7752 - val_loss: 0.5907 - val_accuracy: 0.7758\n",
      "Epoch 12/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5931 - accuracy: 0.7764 - val_loss: 0.5906 - val_accuracy: 0.7769\n",
      "Epoch 13/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5898 - accuracy: 0.7764 - val_loss: 0.5860 - val_accuracy: 0.7800\n",
      "Epoch 14/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5869 - accuracy: 0.7785 - val_loss: 0.5837 - val_accuracy: 0.7802\n",
      "Epoch 15/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5839 - accuracy: 0.7792 - val_loss: 0.6194 - val_accuracy: 0.7691\n",
      "Epoch 16/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5849 - accuracy: 0.7783 - val_loss: 0.5821 - val_accuracy: 0.7761\n",
      "Epoch 17/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5820 - accuracy: 0.7794 - val_loss: 0.5898 - val_accuracy: 0.7756\n",
      "Epoch 18/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5796 - accuracy: 0.7795 - val_loss: 0.5871 - val_accuracy: 0.7754\n",
      "Epoch 19/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5769 - accuracy: 0.7804 - val_loss: 0.5738 - val_accuracy: 0.7825\n",
      "Epoch 20/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5755 - accuracy: 0.7803 - val_loss: 0.5766 - val_accuracy: 0.7805\n",
      "Epoch 21/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5749 - accuracy: 0.7807 - val_loss: 0.5794 - val_accuracy: 0.7761\n",
      "Epoch 22/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5723 - accuracy: 0.7815 - val_loss: 0.5742 - val_accuracy: 0.7834\n",
      "Epoch 23/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5708 - accuracy: 0.7826 - val_loss: 0.5700 - val_accuracy: 0.7848\n",
      "Epoch 24/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5703 - accuracy: 0.7820 - val_loss: 0.5811 - val_accuracy: 0.7826\n",
      "Epoch 25/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5686 - accuracy: 0.7830 - val_loss: 0.5823 - val_accuracy: 0.7834\n",
      "Epoch 26/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5680 - accuracy: 0.7844 - val_loss: 0.5823 - val_accuracy: 0.7766\n",
      "Epoch 27/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5659 - accuracy: 0.7834 - val_loss: 0.5747 - val_accuracy: 0.7850\n",
      "Epoch 28/5000\n",
      "3860/3860 [==============================] - 12s 3ms/step - loss: 0.5659 - accuracy: 0.7833 - val_loss: 0.5884 - val_accuracy: 0.7742\n",
      "1287/1287 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.14      0.23       665\n",
      "           1       1.00      0.00      0.00       583\n",
      "           2       0.44      0.07      0.12      4088\n",
      "           3       0.60      0.91      0.73     11057\n",
      "           4       0.83      0.82      0.83      6056\n",
      "           5       1.00      0.97      0.99     14755\n",
      "           6       0.79      0.67      0.73      3496\n",
      "           7       0.62      0.22      0.33       415\n",
      "           8       0.70      0.13      0.22        54\n",
      "\n",
      "    accuracy                           0.78     41169\n",
      "   macro avg       0.74      0.44      0.46     41169\n",
      "weighted avg       0.78      0.78      0.75     41169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_ohe.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(x_train, y_train_ohe, validation_data=(x_test, y_test_ohe), epochs=5000, callbacks=[early_stopping])\n",
    "model.save('/notebooks/Models/MLP/MLP_001_Unbalanced.h5')\n",
    "\n",
    "model = load_model(\"/notebooks/Models/MLP/MLP_001_Unbalanced.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f76cd9-17bb-4e77-9864-49c90c25b932",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b12a6fc-acf4-45bd-a3b6-7024351b0f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:58:03.460356Z",
     "iopub.status.busy": "2023-06-21T06:58:03.460108Z",
     "iopub.status.idle": "2023-06-21T07:07:45.129705Z",
     "shell.execute_reply": "2023-06-21T07:07:45.128528Z",
     "shell.execute_reply.started": "2023-06-21T06:58:03.460335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11.111111\n",
      "5    11.111111\n",
      "0    11.111111\n",
      "6    11.111111\n",
      "7    11.111111\n",
      "8    11.111111\n",
      "2    11.111111\n",
      "4    11.111111\n",
      "3    11.111111\n",
      "Name: attack_cat, dtype: float64\n",
      "Epoch 1/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 1.0960 - accuracy: 0.5621 - val_loss: 0.8978 - val_accuracy: 0.6531\n",
      "Epoch 2/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.9709 - accuracy: 0.6084 - val_loss: 0.8871 - val_accuracy: 0.6180\n",
      "Epoch 3/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.9212 - accuracy: 0.6308 - val_loss: 0.8507 - val_accuracy: 0.6741\n",
      "Epoch 4/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8922 - accuracy: 0.6421 - val_loss: 0.8165 - val_accuracy: 0.6808\n",
      "Epoch 5/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8733 - accuracy: 0.6513 - val_loss: 0.8269 - val_accuracy: 0.6918\n",
      "Epoch 6/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8594 - accuracy: 0.6567 - val_loss: 0.7871 - val_accuracy: 0.6908\n",
      "Epoch 7/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8480 - accuracy: 0.6623 - val_loss: 0.7867 - val_accuracy: 0.7023\n",
      "Epoch 8/5000\n",
      "12408/12408 [==============================] - 32s 3ms/step - loss: 0.8380 - accuracy: 0.6664 - val_loss: 0.7940 - val_accuracy: 0.7002\n",
      "Epoch 9/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8301 - accuracy: 0.6699 - val_loss: 0.7634 - val_accuracy: 0.7048\n",
      "Epoch 10/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8225 - accuracy: 0.6734 - val_loss: 0.8416 - val_accuracy: 0.6619\n",
      "Epoch 11/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8159 - accuracy: 0.6763 - val_loss: 0.7752 - val_accuracy: 0.7023\n",
      "Epoch 12/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8112 - accuracy: 0.6782 - val_loss: 0.7501 - val_accuracy: 0.7170\n",
      "Epoch 13/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.8055 - accuracy: 0.6800 - val_loss: 0.7690 - val_accuracy: 0.7220\n",
      "Epoch 14/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.8005 - accuracy: 0.6822 - val_loss: 0.7910 - val_accuracy: 0.6975\n",
      "Epoch 15/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.7971 - accuracy: 0.6840 - val_loss: 0.7635 - val_accuracy: 0.7033\n",
      "Epoch 16/5000\n",
      "12408/12408 [==============================] - 34s 3ms/step - loss: 0.7915 - accuracy: 0.6866 - val_loss: 0.7536 - val_accuracy: 0.7154\n",
      "Epoch 17/5000\n",
      "12408/12408 [==============================] - 33s 3ms/step - loss: 0.7881 - accuracy: 0.6884 - val_loss: 0.7628 - val_accuracy: 0.6930\n",
      "1287/1287 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.23      0.15       665\n",
      "           1       0.06      0.33      0.10       583\n",
      "           2       0.35      0.52      0.42      4088\n",
      "           3       0.90      0.42      0.58     11057\n",
      "           4       0.87      0.81      0.84      6056\n",
      "           5       1.00      0.97      0.99     14755\n",
      "           6       0.76      0.80      0.78      3496\n",
      "           7       0.29      0.65      0.40       415\n",
      "           8       0.06      0.76      0.12        54\n",
      "\n",
      "    accuracy                           0.72     41169\n",
      "   macro avg       0.49      0.61      0.49     41169\n",
      "weighted avg       0.83      0.72      0.75     41169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "y_train_ohe = to_categorical(y_train)\n",
    "y_test_ohe = to_categorical(y_test)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train_ohe.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(x_train, y_train_ohe, validation_data=(x_test, y_test_ohe), epochs=5000, callbacks=[early_stopping])\n",
    "model.save('/notebooks/Models/MLP/MLP_001_Balanced.h5')\n",
    "\n",
    "model = load_model(\"/notebooks/Models/MLP/MLP_001_Balanced.h5\")\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
