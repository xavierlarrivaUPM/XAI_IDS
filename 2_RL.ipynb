{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee72e08-eb6a-43af-9839-aa3885a8dd00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:01:53.027465Z",
     "iopub.status.busy": "2023-06-21T15:01:53.027088Z",
     "iopub.status.idle": "2023-06-21T15:01:56.425456Z",
     "shell.execute_reply": "2023-06-21T15:01:56.424143Z",
     "shell.execute_reply.started": "2023-06-21T15:01:53.027436Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra] sb3-contrib imbalanced-learn > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5252d8d-64e5-44d4-a8a1-b81d11ceef01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:15.959571Z",
     "iopub.status.busy": "2023-06-21T17:44:15.958938Z",
     "iopub.status.idle": "2023-06-21T17:44:18.230029Z",
     "shell.execute_reply": "2023-06-21T17:44:18.229288Z",
     "shell.execute_reply.started": "2023-06-21T17:44:15.959544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "\n",
    "from scipy.stats import gmean\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ebad2-7baf-43ad-b9db-f270d6069b31",
   "metadata": {},
   "source": [
    "## Reward factor and minority classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5ebd3d-5d69-402c-9d04-a786b14d258d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:18.802810Z",
     "iopub.status.busy": "2023-06-21T17:44:18.802305Z",
     "iopub.status.idle": "2023-06-21T17:44:19.228509Z",
     "shell.execute_reply": "2023-06-21T17:44:19.227720Z",
     "shell.execute_reply.started": "2023-06-21T17:44:18.802780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.820410868124585, 7.859488354333715, 1.1188476695203153, 0.41002350503963986, 0.7544071834341213, 0.31105872397013934, 1.3080418136180219, 12.520681265206813, 114.35555555555555]\n",
      "[0 1 7 8]\n",
      "5    35.720301\n",
      "3    27.098717\n",
      "4    14.728268\n",
      "2     9.930852\n",
      "6     8.494462\n",
      "0     1.629097\n",
      "1     1.413719\n",
      "7     0.887421\n",
      "8     0.097163\n",
      "Name: attack_cat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top003_train_encoded.csv\")\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "rw_factor = compute_class_weight(class_weight='balanced',\n",
    "                                 classes=np.unique(y_train),\n",
    "                                 y=y_train)\n",
    "\n",
    "rw_factor = rw_factor.tolist()\n",
    "\n",
    "minority_classes = np.where(rw_factor > gmean(rw_factor))[0]\n",
    "\n",
    "print(rw_factor)\n",
    "print(minority_classes)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdf35e-dc81-48f8-94a5-ec0a49a4afac",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea26712-f64b-43d3-9f44-ac7464b9c917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:27.359875Z",
     "iopub.status.busy": "2023-06-21T17:44:27.359521Z",
     "iopub.status.idle": "2023-06-21T17:44:27.368528Z",
     "shell.execute_reply": "2023-06-21T17:44:27.367735Z",
     "shell.execute_reply.started": "2023-06-21T17:44:27.359871Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrainEnv(gym.Env):\n",
    "    def __init__(self, dataset, minority_classes, rw_factor=None):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.x, self.y = dataset\n",
    "        self.minority_classes = minority_classes\n",
    "        self.rw_factor = rw_factor\n",
    "        self.cnt = 0\n",
    "        self.idx = random.randint(0, len(self.x) - 1)\n",
    "        self.action_space = gym.spaces.Discrete(len(np.unique(self.y)))\n",
    "        self.observation_space = gym.spaces.Box(low=-1, high=1,\n",
    "                                                shape=(self.x.shape[1], ),\n",
    "                                                dtype=np.float32)        \n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        \n",
    "        if int(action == self.expected_action):\n",
    "            if self.rw_factor == None:\n",
    "                reward = 1 \n",
    "            else: \n",
    "                reward = self.rw_factor[self.expected_action]\n",
    "        else:\n",
    "            if self.rw_factor == None:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = -self.rw_factor[self.expected_action]\n",
    "            if self.expected_action in self.minority_classes:\n",
    "                done = True\n",
    "                \n",
    "        done = True\n",
    "        \n",
    "        self.cnt += 1\n",
    "        if self.cnt >= len(self.x):\n",
    "            done = True\n",
    "            \n",
    "        self.idx += 1\n",
    "        if self.idx >= len(self.x):\n",
    "            self.idx = 0\n",
    "            \n",
    "        obs = self.seq_observation()\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.seq_observation()\n",
    "        self.cnt = 0\n",
    "        return obs\n",
    "    \n",
    "    def seq_observation(self):        \n",
    "        obs = self.x[self.idx]\n",
    "        self.expected_action = self.y[self.idx]\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562689a2-0491-41e8-b64d-72065ca546a3",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a43aa8c-fc3e-4e83-911b-8e71d6a569f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:29.880500Z",
     "iopub.status.busy": "2023-06-21T17:44:29.880184Z",
     "iopub.status.idle": "2023-06-21T17:44:29.887609Z",
     "shell.execute_reply": "2023-06-21T17:44:29.886906Z",
     "shell.execute_reply.started": "2023-06-21T17:44:29.880477Z"
    }
   },
   "outputs": [],
   "source": [
    "class SaveBest(BaseCallback):\n",
    "    def __init__(self, check_freq: int, log_dir: str, eval_set, name: str, verbose: int = 0, patience: int = 50, max_score=-np.inf):\n",
    "        super(SaveBest, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, name)        \n",
    "        self.max_score = max_score\n",
    "        self.patience = patience\n",
    "        self.failures = 0\n",
    "        self.x_test, self.y_test = eval_set\n",
    "            \n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            y_pred, _ = self.model.predict(self.x_test, deterministic=True)\n",
    "            current_score = metrics.f1_score(self.y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "            diff = current_score - self.max_score\n",
    "            \n",
    "            if diff >= 0.001:\n",
    "                self.max_score = current_score\n",
    "                print(f'New best F1 score at {self.num_timesteps}: {self.max_score}')\n",
    "                # print(classification_report(self.y_test, y_pred, zero_division=0))\n",
    "                print('----- ----- -----')\n",
    "                self.model.save(self.save_path)\n",
    "                self.failures = 0\n",
    "            \n",
    "            else:\n",
    "                self.failures += 1\n",
    "                # print(f'Same F1 score at {self.num_timesteps}: {self.max_score}')\n",
    "                # print('----- ----- -----')\n",
    "                if self.failures >= self.patience:\n",
    "                    print(f'Early training stop at {self.num_timesteps}')\n",
    "                    return False\n",
    "            \n",
    "            return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7308bc-d55f-4126-9304-482d2e3b673e",
   "metadata": {},
   "source": [
    "## Parallel environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bc3908-f58a-4e3b-b185-190e133bb5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:32.377116Z",
     "iopub.status.busy": "2023-06-21T17:44:32.376768Z",
     "iopub.status.idle": "2023-06-21T17:44:32.381824Z",
     "shell.execute_reply": "2023-06-21T17:44:32.381144Z",
     "shell.execute_reply.started": "2023-06-21T17:44:32.377085Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_env(rank, dataset, rw_factor, minority_classes, seed=0):\n",
    "    def _init():\n",
    "        env = TrainEnv(dataset=dataset, rw_factor=None, minority_classes=minority_classes)\n",
    "        env = Monitor(env, './')\n",
    "        env.seed(seed + rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "n_parallel_env = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ed6f9-b625-4ef8-b6e2-716d7c61e886",
   "metadata": {},
   "source": [
    "## 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ceeb279-ac3c-4e82-89e2-c354590b7eb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:38.807009Z",
     "iopub.status.busy": "2023-06-21T17:44:38.806670Z",
     "iopub.status.idle": "2023-06-21T17:44:39.272372Z",
     "shell.execute_reply": "2023-06-21T17:44:39.271411Z",
     "shell.execute_reply.started": "2023-06-21T17:44:38.806998Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123504, 22)\n",
      "(123504,)\n",
      "(41169, 22)\n",
      "(41169,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top003_train_encoded.csv\")\n",
    "test = pd.read_csv(\"/notebooks/FinalDataset/top003_test_encoded.csv\")\n",
    "\n",
    "x_train = train.drop('attack_cat', axis=1)\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "x_test = test.drop('attack_cat', axis=1)\n",
    "y_test = test['attack_cat']\n",
    "\n",
    "del train, test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91810f-c4d3-4118-b523-b5c7f8657e5a",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3103243-9645-4a78-9661-dd590a1eb211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T12:47:02.218509Z",
     "iopub.status.busy": "2023-06-21T12:47:02.218265Z",
     "iopub.status.idle": "2023-06-21T12:47:02.228319Z",
     "shell.execute_reply": "2023-06-21T12:47:02.227607Z",
     "shell.execute_reply.started": "2023-06-21T12:47:02.218486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5295cab3-24d4-4973-bbc6-0ace4d097222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T12:47:02.229422Z",
     "iopub.status.busy": "2023-06-21T12:47:02.229210Z",
     "iopub.status.idle": "2023-06-21T13:12:07.462527Z",
     "shell.execute_reply": "2023-06-21T13:12:07.461247Z",
     "shell.execute_reply.started": "2023-06-21T12:47:02.229402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best F1 score at 8000: 0.031374123827568864\n",
      "----- ----- -----\n",
      "New best F1 score at 24000: 0.21097027599912668\n",
      "----- ----- -----\n",
      "New best F1 score at 40000: 0.2258962711070274\n",
      "----- ----- -----\n",
      "New best F1 score at 56000: 0.23650045820163149\n",
      "----- ----- -----\n",
      "New best F1 score at 72000: 0.24333462883132087\n",
      "----- ----- -----\n",
      "New best F1 score at 88000: 0.27056283946369775\n",
      "----- ----- -----\n",
      "New best F1 score at 104000: 0.27098165293611526\n",
      "----- ----- -----\n",
      "New best F1 score at 120000: 0.2866390033802586\n",
      "----- ----- -----\n",
      "New best F1 score at 136000: 0.30834977541480374\n",
      "----- ----- -----\n",
      "New best F1 score at 152000: 0.3096915739723109\n",
      "----- ----- -----\n",
      "New best F1 score at 168000: 0.31004517933585163\n",
      "----- ----- -----\n",
      "New best F1 score at 216000: 0.31015523627408\n",
      "----- ----- -----\n",
      "New best F1 score at 232000: 0.3121613396242529\n",
      "----- ----- -----\n",
      "New best F1 score at 248000: 0.31307764354979856\n",
      "----- ----- -----\n",
      "New best F1 score at 264000: 0.31345037133023823\n",
      "----- ----- -----\n",
      "New best F1 score at 280000: 0.3147007991179391\n",
      "----- ----- -----\n",
      "New best F1 score at 296000: 0.31499535645499505\n",
      "----- ----- -----\n",
      "New best F1 score at 312000: 0.31562999978096307\n",
      "----- ----- -----\n",
      "New best F1 score at 328000: 0.3182409372035672\n",
      "----- ----- -----\n",
      "New best F1 score at 400000: 0.3207049739239092\n",
      "----- ----- -----\n",
      "New best F1 score at 416000: 0.32118665193633245\n",
      "----- ----- -----\n",
      "New best F1 score at 432000: 0.32208952404937397\n",
      "----- ----- -----\n",
      "New best F1 score at 464000: 0.3223761158330395\n",
      "----- ----- -----\n",
      "New best F1 score at 528000: 0.32467593187606286\n",
      "----- ----- -----\n",
      "New best F1 score at 544000: 0.32477642209614416\n",
      "----- ----- -----\n",
      "New best F1 score at 560000: 0.3281091636496442\n",
      "----- ----- -----\n",
      "New best F1 score at 696000: 0.33259567004740576\n",
      "----- ----- -----\n",
      "New best F1 score at 824000: 0.33377150351814033\n",
      "----- ----- -----\n",
      "New best F1 score at 840000: 0.33433053424455356\n",
      "----- ----- -----\n",
      "New best F1 score at 856000: 0.33565131067380427\n",
      "----- ----- -----\n",
      "New best F1 score at 888000: 0.335994694226636\n",
      "----- ----- -----\n",
      "New best F1 score at 936000: 0.33788788061710473\n",
      "----- ----- -----\n",
      "New best F1 score at 1000000: 0.3388855166151541\n",
      "----- ----- -----\n",
      "New best F1 score at 1016000: 0.3394149808982764\n",
      "----- ----- -----\n",
      "New best F1 score at 1104000: 0.33943026996217635\n",
      "----- ----- -----\n",
      "Early training stop at 1504000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       665\n",
      "           1       0.00      0.00      0.00       583\n",
      "           2       0.38      0.06      0.10      4088\n",
      "           3       0.58      0.82      0.68     11057\n",
      "           4       0.71      0.75      0.73      6056\n",
      "           5       0.99      0.97      0.98     14755\n",
      "           6       0.53      0.60      0.56      3496\n",
      "           7       0.00      0.00      0.00       415\n",
      "           8       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.74     41169\n",
      "   macro avg       0.35      0.36      0.34     41169\n",
      "weighted avg       0.70      0.74      0.70     41169\n",
      "\n",
      "[[    0     0    31   465   162     0     7     0     0]\n",
      " [    0     0    23   369   123     0    68     0     0]\n",
      " [    0     0   235  3343   260     2   248     0     0]\n",
      " [    0     0   241  9067   812    31   906     0     0]\n",
      " [    0     0    27  1028  4559    60   382     0     0]\n",
      " [    0     0     0   320    62 14347    26     0     0]\n",
      " [    0     0    58   990   346     1  2101     0     0]\n",
      " [    0     0     0   128    65     0   222     0     0]\n",
      " [    0     0     0    49     2     0     3     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "env = SubprocVecEnv([make_env(i, dataset=(x_train.values, y_train.values), \n",
    "                              rw_factor=None, minority_classes=minority_classes) for i in range(n_parallel_env)])\n",
    "\n",
    "env.reset()\n",
    "\n",
    "callback = SaveBest(check_freq=1000, log_dir=\"/notebooks/Models/RL\", eval_set=(x_test, y_test), name=\"RL_003_Unbalanced\")\n",
    "\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            device=\"cuda\")\n",
    "\n",
    "model.learn(total_timesteps=5e6,\n",
    "            callback=callback)\n",
    "\n",
    "model = PPO.load(\"/notebooks/Models/RL/RL_003_Unbalanced\",\n",
    "                   device=\"cuda\")\n",
    "y_pred, _ = model.predict(x_test, deterministic=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59284107-c58f-415d-9b04-c93674ddf17e",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fe6fc6-c90e-4a28-b606-ecd44fd3b542",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T17:44:48.774154Z",
     "iopub.status.busy": "2023-06-21T17:44:48.773809Z",
     "iopub.status.idle": "2023-06-21T18:06:01.842859Z",
     "shell.execute_reply": "2023-06-21T18:06:01.841491Z",
     "shell.execute_reply.started": "2023-06-21T17:44:48.774129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11.111111\n",
      "5    11.111111\n",
      "0    11.111111\n",
      "6    11.111111\n",
      "7    11.111111\n",
      "8    11.111111\n",
      "2    11.111111\n",
      "4    11.111111\n",
      "3    11.111111\n",
      "Name: attack_cat, dtype: float64\n",
      "New best F1 score at 8000: 0.031374123827568864\n",
      "----- ----- -----\n",
      "New best F1 score at 24000: 0.29451802355876033\n",
      "----- ----- -----\n",
      "New best F1 score at 168000: 0.30727814228432204\n",
      "----- ----- -----\n",
      "New best F1 score at 184000: 0.3095614241061741\n",
      "----- ----- -----\n",
      "New best F1 score at 200000: 0.3150830337027636\n",
      "----- ----- -----\n",
      "New best F1 score at 328000: 0.32482166083190456\n",
      "----- ----- -----\n",
      "New best F1 score at 368000: 0.3348677120851134\n",
      "----- ----- -----\n",
      "New best F1 score at 384000: 0.3388967865246352\n",
      "----- ----- -----\n",
      "New best F1 score at 416000: 0.3427033993931456\n",
      "----- ----- -----\n",
      "New best F1 score at 432000: 0.3470447487651249\n",
      "----- ----- -----\n",
      "New best F1 score at 448000: 0.35251886961829404\n",
      "----- ----- -----\n",
      "New best F1 score at 480000: 0.37068925083387233\n",
      "----- ----- -----\n",
      "New best F1 score at 608000: 0.380930699936422\n",
      "----- ----- -----\n",
      "New best F1 score at 840000: 0.3887764049525671\n",
      "----- ----- -----\n",
      "New best F1 score at 856000: 0.39691980187522086\n",
      "----- ----- -----\n",
      "New best F1 score at 888000: 0.40289525916318775\n",
      "----- ----- -----\n",
      "New best F1 score at 904000: 0.4056262819634369\n",
      "----- ----- -----\n",
      "New best F1 score at 920000: 0.41111543419259267\n",
      "----- ----- -----\n",
      "Early training stop at 1320000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.16      0.17       665\n",
      "           1       0.11      0.24      0.15       583\n",
      "           2       0.34      0.60      0.44      4088\n",
      "           3       0.79      0.35      0.49     11057\n",
      "           4       0.78      0.70      0.74      6056\n",
      "           5       0.99      0.97      0.98     14755\n",
      "           6       0.52      0.57      0.55      3496\n",
      "           7       0.08      0.40      0.14       415\n",
      "           8       0.02      0.78      0.05        54\n",
      "\n",
      "    accuracy                           0.66     41169\n",
      "   macro avg       0.43      0.53      0.41     41169\n",
      "weighted avg       0.77      0.66      0.69     41169\n",
      "\n",
      "[[  105   132   338    26    37     0     7    18     2]\n",
      " [    1   139   296    10    24     0    65    38    10]\n",
      " [   28   295  2447   421   183     9   266   286   153]\n",
      " [  241   437  2986  3878   607    36   889   817  1166]\n",
      " [  111   283   535    75  4247    68   349   277   111]\n",
      " [   17     1    68    55    48 14347    32    64   123]\n",
      " [   35    31   436   415   246     1  1995   266    71]\n",
      " [    0     0     8     0    42     0   198   164     3]\n",
      " [    1     0     0     2     0     0     3     6    42]]\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "env = SubprocVecEnv([make_env(i, dataset=(x_train.values, y_train.values), \n",
    "                              rw_factor=None, minority_classes=minority_classes) for i in range(n_parallel_env)])\n",
    "\n",
    "env.reset()\n",
    "\n",
    "callback = SaveBest(check_freq=1000, log_dir=\"/notebooks/Models/RL\", eval_set=(x_test, y_test), name=\"RL_003_Balanced\")\n",
    "\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            device=\"cuda\")\n",
    "\n",
    "model.learn(total_timesteps=5e6,\n",
    "            callback=callback)\n",
    "\n",
    "model = PPO.load(\"/notebooks/Models/RL/RL_003_Balanced\",\n",
    "                   device=\"cuda\")\n",
    "y_pred, _ = model.predict(x_test, deterministic=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e29836-5ad5-4a5c-bb19-b1c477ae8b24",
   "metadata": {},
   "source": [
    "## 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef531794-6e00-47f0-929f-3997af8dd9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T18:06:01.845428Z",
     "iopub.status.busy": "2023-06-21T18:06:01.845092Z",
     "iopub.status.idle": "2023-06-21T18:06:03.431742Z",
     "shell.execute_reply": "2023-06-21T18:06:03.430725Z",
     "shell.execute_reply.started": "2023-06-21T18:06:01.845380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123504, 154)\n",
      "(123504,)\n",
      "(41169, 154)\n",
      "(41169,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top002_train_encoded.csv\")\n",
    "test = pd.read_csv(\"/notebooks/FinalDataset/top002_test_encoded.csv\")\n",
    "\n",
    "x_train = train.drop('attack_cat', axis=1)\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "x_test = test.drop('attack_cat', axis=1)\n",
    "y_test = test['attack_cat']\n",
    "\n",
    "del train, test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581ea5b-9dd5-472e-a84d-f1386204f6be",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2568e598-cdd5-433e-b61f-ba3699d4ac05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:07:11.932900Z",
     "iopub.status.busy": "2023-06-21T15:07:11.932065Z",
     "iopub.status.idle": "2023-06-21T15:29:53.694464Z",
     "shell.execute_reply": "2023-06-21T15:29:53.693635Z",
     "shell.execute_reply.started": "2023-06-21T15:07:11.932885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best F1 score at 8000: 0.06248339818900403\n",
      "----- ----- -----\n",
      "New best F1 score at 24000: 0.2974124781916323\n",
      "----- ----- -----\n",
      "New best F1 score at 40000: 0.32567643101881283\n",
      "----- ----- -----\n",
      "New best F1 score at 88000: 0.34007118012323007\n",
      "----- ----- -----\n",
      "New best F1 score at 104000: 0.3443251316523072\n",
      "----- ----- -----\n",
      "New best F1 score at 168000: 0.348157188171964\n",
      "----- ----- -----\n",
      "New best F1 score at 216000: 0.3491721922228718\n",
      "----- ----- -----\n",
      "New best F1 score at 248000: 0.35049144421689316\n",
      "----- ----- -----\n",
      "New best F1 score at 264000: 0.35328496840549334\n",
      "----- ----- -----\n",
      "New best F1 score at 432000: 0.3552712253129255\n",
      "----- ----- -----\n",
      "New best F1 score at 512000: 0.3668564133713813\n",
      "----- ----- -----\n",
      "New best F1 score at 608000: 0.3691435874542734\n",
      "----- ----- -----\n",
      "New best F1 score at 624000: 0.3716543882367617\n",
      "----- ----- -----\n",
      "New best F1 score at 696000: 0.37509897663426034\n",
      "----- ----- -----\n",
      "New best F1 score at 712000: 0.3766170745818781\n",
      "----- ----- -----\n",
      "New best F1 score at 744000: 0.38131251528156207\n",
      "----- ----- -----\n",
      "New best F1 score at 840000: 0.38416603341897937\n",
      "----- ----- -----\n",
      "New best F1 score at 904000: 0.3851764808255487\n",
      "----- ----- -----\n",
      "New best F1 score at 920000: 0.38852295094959305\n",
      "----- ----- -----\n",
      "Early training stop at 1320000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       665\n",
      "           1       0.00      0.00      0.00       583\n",
      "           2       0.27      0.05      0.08      4088\n",
      "           3       0.59      0.91      0.71     11057\n",
      "           4       0.81      0.77      0.79      6056\n",
      "           5       0.99      0.97      0.98     14755\n",
      "           6       0.73      0.61      0.67      3496\n",
      "           7       0.53      0.18      0.27       415\n",
      "           8       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.76     41169\n",
      "   macro avg       0.44      0.39      0.39     41169\n",
      "weighted avg       0.73      0.76      0.73     41169\n",
      "\n",
      "[[    0     0    42   605    18     0     0     0     0]\n",
      " [    0     0    32   492    22     0    37     0     0]\n",
      " [    0     0   185  3678   111    21    75    18     0]\n",
      " [    0     0   317 10082   463     7   164    24     0]\n",
      " [    0     0    58   998  4633    80   270    17     0]\n",
      " [    0     0     3   313    61 14363    11     4     0]\n",
      " [    0     0    38   987   324     5  2142     0     0]\n",
      " [    0     0     0    30    82     0   228    75     0]\n",
      " [    0     0     0    44     4     0     3     3     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "env = SubprocVecEnv([make_env(i, dataset=(x_train.values, y_train.values), \n",
    "                              rw_factor=None, minority_classes=minority_classes) for i in range(n_parallel_env)])\n",
    "\n",
    "env.reset()\n",
    "\n",
    "callback = SaveBest(check_freq=1000, log_dir=\"/notebooks/Models/RL\", eval_set=(x_test, y_test), name=\"RL_002_Unbalanced\")\n",
    "\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            device=\"cuda\")\n",
    "\n",
    "model.learn(total_timesteps=5e6,\n",
    "            callback=callback)\n",
    "\n",
    "model = PPO.load(\"/notebooks/Models/RL/RL_002_Unbalanced\",\n",
    "                   device=\"cuda\")\n",
    "y_pred, _ = model.predict(x_test, deterministic=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9682c2a-ee5c-4d8b-a480-a8fc120470d0",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a93fb983-b849-4b4b-8611-03aa14966394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T18:06:03.433100Z",
     "iopub.status.busy": "2023-06-21T18:06:03.432864Z",
     "iopub.status.idle": "2023-06-21T18:32:40.175677Z",
     "shell.execute_reply": "2023-06-21T18:32:40.172530Z",
     "shell.execute_reply.started": "2023-06-21T18:06:03.433079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11.111111\n",
      "5    11.111111\n",
      "0    11.111111\n",
      "6    11.111111\n",
      "7    11.111111\n",
      "8    11.111111\n",
      "2    11.111111\n",
      "4    11.111111\n",
      "3    11.111111\n",
      "Name: attack_cat, dtype: float64\n",
      "New best F1 score at 8000: 0.06248339818900403\n",
      "----- ----- -----\n",
      "New best F1 score at 24000: 0.26851826100340587\n",
      "----- ----- -----\n",
      "New best F1 score at 40000: 0.38336410120911174\n",
      "----- ----- -----\n",
      "New best F1 score at 136000: 0.3909546283801629\n",
      "----- ----- -----\n",
      "New best F1 score at 232000: 0.41614240962540555\n",
      "----- ----- -----\n",
      "New best F1 score at 264000: 0.4235622214428831\n",
      "----- ----- -----\n",
      "New best F1 score at 280000: 0.42988339428888983\n",
      "----- ----- -----\n",
      "New best F1 score at 416000: 0.43107171019735935\n",
      "----- ----- -----\n",
      "New best F1 score at 808000: 0.4361675017718029\n",
      "----- ----- -----\n",
      "New best F1 score at 856000: 0.43731929406110776\n",
      "----- ----- -----\n",
      "New best F1 score at 888000: 0.43973347149279046\n",
      "----- ----- -----\n",
      "New best F1 score at 936000: 0.44261161139690025\n",
      "----- ----- -----\n",
      "New best F1 score at 1016000: 0.4466678120782375\n",
      "----- ----- -----\n",
      "New best F1 score at 1152000: 0.4499660082479083\n",
      "----- ----- -----\n",
      "New best F1 score at 1168000: 0.45188465924099674\n",
      "----- ----- -----\n",
      "New best F1 score at 1216000: 0.45340473893335914\n",
      "----- ----- -----\n",
      "Early training stop at 1616000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.26      0.14       665\n",
      "           1       0.05      0.31      0.09       583\n",
      "           2       0.34      0.42      0.37      4088\n",
      "           3       0.88      0.42      0.57     11057\n",
      "           4       0.82      0.77      0.79      6056\n",
      "           5       0.99      0.97      0.98     14755\n",
      "           6       0.77      0.62      0.69      3496\n",
      "           7       0.31      0.55      0.40       415\n",
      "           8       0.02      0.81      0.04        54\n",
      "\n",
      "    accuracy                           0.68     41169\n",
      "   macro avg       0.48      0.57      0.45     41169\n",
      "weighted avg       0.82      0.68      0.73     41169\n",
      "\n",
      "[[  171   209   270    10     4     1     0     0     0]\n",
      " [  108   179   232     5    15     0    28     5    11]\n",
      " [  543  1083  1697   414   109     8    66    49   119]\n",
      " [  793  1356  2175  4649   534     4    88   264  1194]\n",
      " [  121   314   288    45  4663    73   303   138   111]\n",
      " [   10    21    79   148    50 14347    15    19    66]\n",
      " [   79   181   252    11   266     4  2180    25   498]\n",
      " [    0     0     0     3    40     0   139   230     3]\n",
      " [    1     0     0     0     1     0     3     5    44]]\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "env = SubprocVecEnv([make_env(i, dataset=(x_train.values, y_train.values), \n",
    "                              rw_factor=None, minority_classes=minority_classes) for i in range(n_parallel_env)])\n",
    "\n",
    "env.reset()\n",
    "\n",
    "callback = SaveBest(check_freq=1000, log_dir=\"/notebooks/Models/RL\", eval_set=(x_test, y_test), name=\"RL_002_Balanced\")\n",
    "\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            device=\"cuda\")\n",
    "\n",
    "model.learn(total_timesteps=5e6,\n",
    "            callback=callback)\n",
    "\n",
    "model = PPO.load(\"/notebooks/Models/RL/RL_002_Balanced\",\n",
    "                   device=\"cuda\")\n",
    "y_pred, _ = model.predict(x_test, deterministic=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61845f0f-1e4d-40ea-8d7d-86341c26aba7",
   "metadata": {},
   "source": [
    "## 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c06a0d-6834-4944-b6b6-8384f7c54972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T18:32:40.177592Z",
     "iopub.status.busy": "2023-06-21T18:32:40.177342Z",
     "iopub.status.idle": "2023-06-21T18:32:41.945596Z",
     "shell.execute_reply": "2023-06-21T18:32:41.944836Z",
     "shell.execute_reply.started": "2023-06-21T18:32:40.177569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123504, 168)\n",
      "(123504,)\n",
      "(41169, 168)\n",
      "(41169,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"/notebooks/FinalDataset/top001_train_encoded.csv\")\n",
    "test = pd.read_csv(\"/notebooks/FinalDataset/top001_test_encoded.csv\")\n",
    "\n",
    "x_train = train.drop('attack_cat', axis=1)\n",
    "y_train = train['attack_cat']\n",
    "\n",
    "x_test = test.drop('attack_cat', axis=1)\n",
    "y_test = test['attack_cat']\n",
    "\n",
    "del train, test\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaa134c-7fe6-4b40-9c37-9726ff8a4041",
   "metadata": {},
   "source": [
    "### Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b355671a-7c3c-4dd9-888e-ad3aa832eb40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T15:58:58.709115Z",
     "iopub.status.busy": "2023-06-21T15:58:58.708854Z",
     "iopub.status.idle": "2023-06-21T16:19:45.760591Z",
     "shell.execute_reply": "2023-06-21T16:19:45.759927Z",
     "shell.execute_reply.started": "2023-06-21T15:58:58.709092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best F1 score at 8000: 0.004977402259557516\n",
      "----- ----- -----\n",
      "New best F1 score at 24000: 0.269861871508707\n",
      "----- ----- -----\n",
      "New best F1 score at 40000: 0.27101956926538034\n",
      "----- ----- -----\n",
      "New best F1 score at 56000: 0.2812861378740166\n",
      "----- ----- -----\n",
      "New best F1 score at 72000: 0.31226619805037975\n",
      "----- ----- -----\n",
      "New best F1 score at 88000: 0.3316931189805285\n",
      "----- ----- -----\n",
      "New best F1 score at 104000: 0.33826705376956645\n",
      "----- ----- -----\n",
      "New best F1 score at 120000: 0.34454247451006964\n",
      "----- ----- -----\n",
      "New best F1 score at 136000: 0.3461584126744963\n",
      "----- ----- -----\n",
      "New best F1 score at 152000: 0.34876061113093715\n",
      "----- ----- -----\n",
      "New best F1 score at 168000: 0.3522749859012811\n",
      "----- ----- -----\n",
      "New best F1 score at 232000: 0.3533117340115342\n",
      "----- ----- -----\n",
      "New best F1 score at 312000: 0.3566733968603422\n",
      "----- ----- -----\n",
      "New best F1 score at 496000: 0.35785437464006264\n",
      "----- ----- -----\n",
      "New best F1 score at 560000: 0.3725078649172206\n",
      "----- ----- -----\n",
      "New best F1 score at 696000: 0.38186364710393256\n",
      "----- ----- -----\n",
      "New best F1 score at 824000: 0.38693336315972726\n",
      "----- ----- -----\n",
      "Early training stop at 1224000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       665\n",
      "           1       0.00      0.00      0.00       583\n",
      "           2       0.26      0.02      0.04      4088\n",
      "           3       0.60      0.89      0.71     11057\n",
      "           4       0.80      0.80      0.80      6056\n",
      "           5       1.00      0.97      0.98     14755\n",
      "           6       0.66      0.71      0.69      3496\n",
      "           7       0.52      0.17      0.26       415\n",
      "           8       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.77     41169\n",
      "   macro avg       0.43      0.40      0.39     41169\n",
      "weighted avg       0.72      0.77      0.73     41169\n",
      "\n",
      "[[    0     0    21   623    19     0     2     0     0]\n",
      " [    0     0    16   509    20     0    38     0     0]\n",
      " [    0     0    89  3702   142    28   112    15     0]\n",
      " [    0     0   161  9822   546     6   495    27     0]\n",
      " [    0     0    27   786  4844     4   379    16     0]\n",
      " [    0     0     3   296    77 14355    20     4     0]\n",
      " [    0     0    23   647   316    11  2498     1     0]\n",
      " [    0     0     0    18    77     0   249    71     0]\n",
      " [    0     0     0    44     5     0     3     2     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "env = SubprocVecEnv([make_env(i, dataset=(x_train.values, y_train.values), \n",
    "                              rw_factor=None, minority_classes=minority_classes) for i in range(n_parallel_env)])\n",
    "\n",
    "env.reset()\n",
    "\n",
    "callback = SaveBest(check_freq=1000, log_dir=\"/notebooks/Models/RL\", eval_set=(x_test, y_test), name=\"RL_001_Unbalanced\")\n",
    "\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            device=\"cuda\")\n",
    "\n",
    "model.learn(total_timesteps=5e6,\n",
    "            callback=callback)\n",
    "\n",
    "model = PPO.load(\"/notebooks/Models/RL/RL_001_Unbalanced\",\n",
    "                   device=\"cuda\")\n",
    "y_pred, _ = model.predict(x_test, deterministic=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc25ce6-906e-410b-b337-d0ca1e50eca0",
   "metadata": {},
   "source": [
    "### Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "489f57d2-604b-4102-acb8-76ca6c101c58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T18:32:41.949508Z",
     "iopub.status.busy": "2023-06-21T18:32:41.949283Z",
     "iopub.status.idle": "2023-06-21T18:59:14.487066Z",
     "shell.execute_reply": "2023-06-21T18:59:14.486006Z",
     "shell.execute_reply.started": "2023-06-21T18:32:41.949487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11.111111\n",
      "5    11.111111\n",
      "0    11.111111\n",
      "6    11.111111\n",
      "7    11.111111\n",
      "8    11.111111\n",
      "2    11.111111\n",
      "4    11.111111\n",
      "3    11.111111\n",
      "Name: attack_cat, dtype: float64\n",
      "New best F1 score at 8000: 0.004977402259557516\n",
      "----- ----- -----\n",
      "New best F1 score at 24000: 0.3495081034789635\n",
      "----- ----- -----\n",
      "New best F1 score at 40000: 0.37333170601711985\n",
      "----- ----- -----\n",
      "New best F1 score at 56000: 0.39712282960590695\n",
      "----- ----- -----\n",
      "New best F1 score at 232000: 0.40018223698967914\n",
      "----- ----- -----\n",
      "New best F1 score at 248000: 0.406147225554882\n",
      "----- ----- -----\n",
      "New best F1 score at 264000: 0.4093807975555897\n",
      "----- ----- -----\n",
      "New best F1 score at 280000: 0.4110802786604639\n",
      "----- ----- -----\n",
      "New best F1 score at 328000: 0.4188704120435577\n",
      "----- ----- -----\n",
      "New best F1 score at 384000: 0.43553736172351254\n",
      "----- ----- -----\n",
      "New best F1 score at 416000: 0.44256815680357897\n",
      "----- ----- -----\n",
      "New best F1 score at 432000: 0.44720356446211273\n",
      "----- ----- -----\n",
      "New best F1 score at 560000: 0.4520030096929016\n",
      "----- ----- -----\n",
      "New best F1 score at 640000: 0.45727552452797326\n",
      "----- ----- -----\n",
      "New best F1 score at 728000: 0.4585480219176621\n",
      "----- ----- -----\n",
      "New best F1 score at 1104000: 0.4635819928817075\n",
      "----- ----- -----\n",
      "New best F1 score at 1120000: 0.4689219439290126\n",
      "----- ----- -----\n",
      "New best F1 score at 1200000: 0.47204271408156373\n",
      "----- ----- -----\n",
      "Early training stop at 1600000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.23      0.17       665\n",
      "           1       0.05      0.30      0.09       583\n",
      "           2       0.34      0.47      0.40      4088\n",
      "           3       0.88      0.44      0.58     11057\n",
      "           4       0.85      0.74      0.79      6056\n",
      "           5       1.00      0.97      0.99     14755\n",
      "           6       0.67      0.78      0.72      3496\n",
      "           7       0.33      0.63      0.43       415\n",
      "           8       0.04      0.85      0.08        54\n",
      "\n",
      "    accuracy                           0.70     41169\n",
      "   macro avg       0.48      0.60      0.47     41169\n",
      "weighted avg       0.82      0.70      0.74     41169\n",
      "\n",
      "[[  154   196   297    16     1     0     1     0     0]\n",
      " [   84   175   254    12    11     0    31    10     6]\n",
      " [  342  1034  1921   438   101     1    99    58    94]\n",
      " [  464  1296  2432  4842   448     3   558   234   780]\n",
      " [   92   313   295    51  4507     4   520   176    98]\n",
      " [    6    16   102   144    55 14337    16    14    65]\n",
      " [   50   179   287    12   161     0  2721    31    55]\n",
      " [    0     0     0     2    29     0   113   261    10]\n",
      " [    0     0     0     1     2     0     3     2    46]]\n"
     ]
    }
   ],
   "source": [
    "oversample = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
    "\n",
    "proportions = y_train.value_counts(normalize=True) * 100\n",
    "print(proportions)\n",
    "\n",
    "env = SubprocVecEnv([make_env(i, dataset=(x_train.values, y_train.values), \n",
    "                              rw_factor=None, minority_classes=minority_classes) for i in range(n_parallel_env)])\n",
    "\n",
    "env.reset()\n",
    "\n",
    "callback = SaveBest(check_freq=1000, log_dir=\"/notebooks/Models/RL\", eval_set=(x_test, y_test), name=\"RL_001_Balanced\")\n",
    "\n",
    "model = PPO(policy='MlpPolicy',\n",
    "            env=env,\n",
    "            device=\"cuda\")\n",
    "\n",
    "model.learn(total_timesteps=5e6,\n",
    "            callback=callback)\n",
    "\n",
    "model = PPO.load(\"/notebooks/Models/RL/RL_001_Balanced\",\n",
    "                   device=\"cuda\")\n",
    "y_pred, _ = model.predict(x_test, deterministic=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
